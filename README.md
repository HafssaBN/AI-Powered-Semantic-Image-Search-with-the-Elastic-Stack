# ELK Stack for Image Similarity Search

This project is a full-stack web application that allows you to search for images based on their conceptual meaning, not just tags or filenames. You can search using either a text description (e.g., "a blue butterfly on a flower") or by uploading another image.

The entire application and its monitoring backend are fully containerized using Docker Compose, creating a complete, end-to-end, and reproducible MLOps environment.

![Screenshot](PATH_TO_YOUR_SCREENSHOT.png)  
*(Replace with a screenshot of your successful search results)*

---

## ‚ú® Features

- **Multi-Modal Semantic Search**: Search for images using either a text query or an image query.  
- **AI-Powered Embeddings**: Utilizes the pre-trained CLIP model (ViT-B-32) from `sentence-transformers` to generate 512-dimensional vector embeddings for both text and images.  
- **High-Speed Vector Search**: Uses Elasticsearch as a vector database to perform efficient k-Nearest Neighbor (k-NN) similarity searches.  
- **Interactive Visualization**: A 2D semantic map of all indexed images, created using UMAP for dimensionality reduction and Plotly for interactive plotting.  
- **Full Observability Stack**: The system is monitored by the Elastic Stack (Filebeat, Logstash, Elasticsearch, Kibana) for centralized logging and diagnostics.  
- **Containerized & Reproducible**: The entire 5-service stack is defined in a single `docker-compose.yml` file for easy, one-command deployment.  

---

## üõ†Ô∏è Tech Stack & Architecture

### **Core Application**
- **Backend**: Python 3.9, Flask  
- **AI Model**: `sentence-transformers` (CLIP)  
- **Image Processing**: Pillow  
- **Visualization**: UMAP, Plotly, NumPy  

### **Database & Search**
- **Vector Store**: Elasticsearch 8.14.1  

### **Observability Stack**
- **Log Collection**: Filebeat  
- **Log Processing & Enrichment**: Logstash  
- **Log Storage & Analysis**: Elasticsearch  
- **Visualization & Dashboards**: Kibana  

### **DevOps**
- **Containerization**: Docker & Docker Compose  

---

## üìÇ Project Structure

```

image-search-app/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ filebeat/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ filebeat.yml          # Configures Filebeat to collect logs
‚îÇ   ‚îî‚îÄ‚îÄ logstash/
‚îÇ       ‚îî‚îÄ‚îÄ pipeline/
‚îÇ           ‚îî‚îÄ‚îÄ logstash.conf     # Configures the Logstash processing pipeline
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ images/                   # Your images go here
‚îÇ   ‚îî‚îÄ‚îÄ uploads/                  # Query images are temporarily stored here
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ index.html                # Main search page
‚îÇ   ‚îú‚îÄ‚îÄ style.html                # CSS style
‚îÇ   ‚îî‚îÄ‚îÄ visualize.html            # Visualization page
‚îú‚îÄ‚îÄ app.py                        # The main Flask application logic
‚îú‚îÄ‚îÄ docker-compose.yml            # Defines and orchestrates all 5 services
‚îú‚îÄ‚îÄ Dockerfile                    # Builds the Python/Flask application container
‚îî‚îÄ‚îÄ requirements.txt              # Python dependencies

````

---

## üöÄ Getting Started

### **Prerequisites**
- Git  
- Docker  
- Docker Desktop (or Docker installed on Linux)  
> **Important**: Ensure Docker Desktop has at least 6‚Äì8 GB of memory allocated (`Settings > Resources`).  

---

### **Installation & Setup**

**1Ô∏è‚É£ Clone the repository**
```bash
git clone <this repo>
cd image-search-app
````

**2Ô∏è‚É£ Create necessary directories**
Ensure the `config/` directories and `static/images` directory exist as shown above.

**3Ô∏è‚É£ Add your images**
Place searchable images inside:

```
static/images/
```

**4Ô∏è‚É£ Build and run the stack**

```bash
docker-compose up --build
```

The first run will download model weights and images, so it may take several minutes.

---

## üìå How to Use

1. **Access the Image Search App**

   * [http://localhost:5001](http://localhost:5001)

2. **Index Your Images (CRITICAL FIRST STEP)**

   * Click the **"Index All Images"** button in the web app.
   * Watch logs to confirm indexing.

3. **Search**

   * Use the **text search box** or **upload an image** to find conceptually similar results.

4. **Explore the System**

   * **Kibana (Logging UI)**: [http://localhost:5601](http://localhost:5601)
   * **Elasticsearch (Database API)**: [http://localhost:9200](http://localhost:9200)
   * **Visualization Map**: [http://localhost:5001/visualize](http://localhost:5001/visualize)

---

## üõ£Ô∏è Future Enhancements (Roadmap)

* Fine-tune the CLIP model for domain-specific datasets.
* Implement hybrid search (vector + keyword).
* Build Kibana dashboards for Flask log metrics.
* Scale the system for larger datasets with multiple Elasticsearch nodes.

---

## üìÑ License

This project is licensed under the **MIT License**. See the `LICENSE` file for details.

```

‚úÖ **Fixes applied:**
- Proper headings (`##` instead of inline bold for sections).
- Used **lists** for features and stack to avoid walls of text.
- Enclosed **commands and folder structures** in fenced code blocks.
- Removed unnecessary ‚ÄúIGNORE_WHEN_COPYING‚Äù lines.
- Ensured **spacing** for better GitHub rendering.

---

üëâ Question: Do you want me to also add **badges (Docker, Python, Elasticsearch, MIT License, etc.)** at the top for a more professional GitHub README? They make it look polished.
```
